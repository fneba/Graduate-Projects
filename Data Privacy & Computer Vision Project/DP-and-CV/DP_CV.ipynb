{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1:** Download the YOLOv7 repository and install the requirements."
      ],
      "metadata": {
        "id": "TKS4fvHisNY5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-5Oftzka4S0"
      },
      "outputs": [],
      "source": [
        "# Download YOLOv7 repository and install requirements\n",
        "!git clone https://github.com/WongKinYiu/yolov7\n",
        "%cd yolov7\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2:** Download the datasets directly off of Roboflow. extracted0.zip is PKLot, and extracted1.zip is CarPK."
      ],
      "metadata": {
        "id": "EDc0d-MYsaGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab the dataset\n",
        "import requests\n",
        "import os\n",
        "# Direct link to the dataset(s)\n",
        "# 0 is PKLot, 1 is CarPK\n",
        "dataset_url = [\"https://public.roboflow.com/ds/BLqIb30AQq?key=SIb62cQiK1\", \"https://universe.roboflow.com/ds/TBXdF68sRI?key=XgQtOaoTU1\"]\n",
        "\n",
        "# Directory to save the downloaded dataset\n",
        "save_dir = \"roboflow_dataset\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Download the dataset\n",
        "for i in range(2):\n",
        "  response = requests.get(dataset_url[i])\n",
        "  if response.status_code == 200:\n",
        "      with open(os.path.join(save_dir, \"dataset\" + str(i) + \".zip\"), \"wb\") as f:\n",
        "          f.write(response.content)\n",
        "      print(\"Dataset downloaded successfully.\")\n",
        "  else:\n",
        "      print(\"Failed to download dataset.\")"
      ],
      "metadata": {
        "id": "O7HhNK9_bCDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3:** Extract the datasets. There are a few options. To extract both datasets, use lines 25-38. Otherwise, uncomment one of lines 9-12. It does not really matter which one, but later on it makes it possible to come back and re-extract the original dataset."
      ],
      "metadata": {
        "id": "iZZz7gKPslPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the dataset(s)\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# For best_v1\n",
        "zip_file_path = \"roboflow_dataset/dataset\" + str(0) + \".zip\"\n",
        "\n",
        "# Directory to extract the dataset\n",
        "#extracted_dir_path = \"roboflow_dataset/v1_og\"\n",
        "#extracted_dir_path = \"roboflow_dataset/v1_baw\"\n",
        "#extracted_dir_path = \"roboflow_dataset/v1_aug\"\n",
        "extracted_dir_path = \"roboflow_dataset/v1_empty\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(extracted_dir_path, exist_ok=True)\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_dir_path)\n",
        "\n",
        "print(\"Dataset extracted successfully.\")\n",
        "\n",
        "\n",
        "# Path to the downloaded zip file\n",
        "'''for i in range(2):\n",
        "  zip_file_path = \"roboflow_dataset/dataset\" + str(i) + \".zip\"\n",
        "\n",
        "  # Directory to extract the dataset\n",
        "  extracted_dir_path = \"roboflow_dataset/extracted\" + str(i)\n",
        "\n",
        "  # Create the directory if it doesn't exist\n",
        "  os.makedirs(extracted_dir_path, exist_ok=True)\n",
        "\n",
        "  # Extract the zip file\n",
        "  with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "      zip_ref.extractall(extracted_dir_path)\n",
        "\n",
        "  print(\"Dataset extracted successfully.\")'''"
      ],
      "metadata": {
        "id": "mmnu4NP_bJvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4:** Process the data as needed. The first block will convert all images to grayscale. The second will augment the dataset with 90 degree counter-clockwise rotations (note: this doubles the size of the dataset). The third block will get rid of 'space-occupied' labels and turn it into a single object classification problem. The fourth block will combine the datasets if two have been downloaded (note: this does not combine PKLot and CarPK correctly due to CarPK not having 'space-empty' labels, this combo was not used later on in the project)."
      ],
      "metadata": {
        "id": "DYnRz9NIs_-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert images to black and white\n",
        "from PIL import Image\n",
        "\n",
        "# Directory to be converted\n",
        "train_dir_path = \"roboflow_dataset/v1_baw/train/images\"\n",
        "valid_dir_path = \"roboflow_dataset/v1_baw/valid/images\"\n",
        "\n",
        "test_dir_path = \"roboflow_dataset/v1_baw/test/images\"\n",
        "\n",
        "# Training directory\n",
        "'''for name in os.listdir(train_dir_path):\n",
        "  image_file = Image.open(train_dir_path+'/'+name)\n",
        "  image_file = image_file.convert('L')\n",
        "  image_file.save(train_dir_path+'/'+name)'''\n",
        "\n",
        "# Valid directory\n",
        "'''for name in os.listdir(valid_dir_path):\n",
        "  image_file = Image.open(valid_dir_path+'/'+name)\n",
        "  image_file = image_file.convert('L')\n",
        "  image_file.save(valid_dir_path+'/'+name)'''\n",
        "\n",
        "# Test directory\n",
        "for name in os.listdir(test_dir_path):\n",
        "  image_file = Image.open(test_dir_path+'/'+name)\n",
        "  image_file = image_file.convert('L')\n",
        "  image_file.save(test_dir_path+'/'+name)\n"
      ],
      "metadata": {
        "id": "krwVDlVnXoU4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert test images with just 90 degree rotations counterclockwise\n",
        "# This doubles the size of the dataset increasing training time to 6hrs for 20 epochs\n",
        "from PIL import Image\n",
        "\n",
        "def Rotate90(bbox, img_width=640):\n",
        "  # Get the coords of the bbox\n",
        "  lbl, x_min, y_min, x_max, y_max = bbox\n",
        "  x_max += x_min\n",
        "  y_max += y_min\n",
        "\n",
        "  # Rotate\n",
        "  new_xmin = min(max(y_min, 0), 1)\n",
        "  new_ymin = min(max(1 - x_max, 0), 1)\n",
        "  new_xmax = min(max(y_max - new_xmin, 0), 1)\n",
        "  new_ymax = min(max(1 - x_min - new_ymin, 0), 1)\n",
        "\n",
        "  return [lbl, new_xmin, new_ymin, new_xmax, new_ymax]\n",
        "\n",
        "# Directory to be converted\n",
        "train_dir_img = \"roboflow_dataset/v1_aug/train/images\"\n",
        "train_dir_lbl = \"roboflow_dataset/v1_aug/train/labels\"\n",
        "valid_dir_img = \"roboflow_dataset/v1_aug/valid/images\"\n",
        "valid_dir_lbl = \"roboflow_dataset/v1_aug/valid/labels\"\n",
        "\n",
        "test_dir_img = \"roboflow_dataset/v1_aug/test/images\"\n",
        "test_dir_lbl = \"roboflow_dataset/v1_aug/test/labels\"\n",
        "\n",
        "# Training directory\n",
        "c = 0\n",
        "for name in os.listdir(train_dir_img):\n",
        "  image_file = Image.open(train_dir_img+'/'+name)\n",
        "  image_file = image_file.rotate(90)\n",
        "  image_file.save(train_dir_img+'/'+str(c)+name)\n",
        "\n",
        "  # Rotate bounding boxes in the labels file\n",
        "  label_file = train_dir_lbl+'/'+name[:-3]+'txt'\n",
        "  data = []\n",
        "  with open(label_file, 'r', encoding='utf-8') as file:\n",
        "    data = file.readlines()\n",
        "    for count, line in enumerate(data):\n",
        "      line_split = line.split(' ')\n",
        "      # Cut off the newline character\n",
        "      line_split[-1] = line_split[-1][:-2]\n",
        "      line_split = [float(i) for i in line_split]\n",
        "      line_new = Rotate90(line_split)\n",
        "      line_new[0] = int(line_new[0])\n",
        "      line_new = \" \".join(str(item) for item in line_new)\n",
        "      data[count] = line_new+'\\n'\n",
        "\n",
        "  # Save the file\n",
        "  f = open(train_dir_lbl+'/'+str(c)+name[:-3]+'txt', \"w\")\n",
        "  f.write(''.join(data))\n",
        "  f.close()\n",
        "\n",
        "  c += 1\n",
        "\n",
        "\n",
        "# Valid directory\n",
        "c = 0\n",
        "for name in os.listdir(valid_dir_img):\n",
        "  image_file = Image.open(valid_dir_img+'/'+name)\n",
        "  image_file = image_file.rotate(90)\n",
        "  image_file.save(valid_dir_img+'/'+str(c)+name)\n",
        "\n",
        "  # Rotate bounding boxes in the labels file\n",
        "  label_file = valid_dir_lbl+'/'+name[:-3]+'txt'\n",
        "  data = []\n",
        "  with open(label_file, 'r', encoding='utf-8') as file:\n",
        "    data = file.readlines()\n",
        "    for count, line in enumerate(data):\n",
        "      line_split = line.split(' ')\n",
        "      # Cut off the newline character\n",
        "      line_split[-1] = line_split[-1][:-2]\n",
        "      line_split = [float(i) for i in line_split]\n",
        "      line_new = Rotate90(line_split)\n",
        "      line_new[0] = int(line_new[0])\n",
        "      line_new = \" \".join(str(item) for item in line_new)\n",
        "      data[count] = line_new+'\\n'\n",
        "\n",
        "  # Overwrite the file\n",
        "  f = open(valid_dir_lbl+'/'+str(c)+name[:-3]+'txt', \"w\")\n",
        "  f.write(''.join(data))\n",
        "  f.close()\n",
        "\n",
        "  c += 1\n"
      ],
      "metadata": {
        "id": "t42970SqckMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get rid of the space occupied labels - 1\n",
        "\n",
        "# Directory to be converted\n",
        "train_dir_lbl = \"roboflow_dataset/v1_empty/train/labels\"\n",
        "valid_dir_lbl = \"roboflow_dataset/v1_empty/valid/labels\"\n",
        "test_dir_lbl = \"roboflow_dataset/v1_empty/test/labels\"\n",
        "\n",
        "# Training directory\n",
        "for name in os.listdir(train_dir_lbl):\n",
        "  # Get rid of 1s in the labels file\n",
        "  label_file = train_dir_lbl+'/'+name\n",
        "  data = []\n",
        "  with open(label_file, 'r', encoding='utf-8') as file:\n",
        "    line_data = file.readlines()\n",
        "    for line in line_data:\n",
        "      if (line[0] != '1'):\n",
        "        data.append(line)\n",
        "\n",
        "  # Save the file\n",
        "  f = open(train_dir_lbl+'/'+name, \"w\")\n",
        "  f.write(''.join(data))\n",
        "  f.close()\n",
        "\n",
        "# Valid directory\n",
        "for name in os.listdir(valid_dir_lbl):\n",
        "  # Get rid of 1s in the labels file\n",
        "  label_file = valid_dir_lbl+'/'+name\n",
        "  data = []\n",
        "  with open(label_file, 'r', encoding='utf-8') as file:\n",
        "    line_data = file.readlines()\n",
        "    for line in line_data:\n",
        "      if (line[0] != '1'):\n",
        "        data.append(line)\n",
        "\n",
        "  # Save the file\n",
        "  f = open(valid_dir_lbl+'/'+name, \"w\")\n",
        "  f.write(''.join(data))\n",
        "  f.close()\n",
        "\n",
        "# Test directory\n",
        "for name in os.listdir(test_dir_lbl):\n",
        "  # Get rid of 1s in the labels file\n",
        "  label_file = test_dir_lbl+'/'+name\n",
        "  data = []\n",
        "  with open(label_file, 'r', encoding='utf-8') as file:\n",
        "    line_data = file.readlines()\n",
        "    for line in line_data:\n",
        "      if (line[0] != '1'):\n",
        "        data.append(line)\n",
        "\n",
        "  # Save the file\n",
        "  f = open(test_dir_lbl+'/'+name, \"w\")\n",
        "  f.write(''.join(data))\n",
        "  f.close()\n"
      ],
      "metadata": {
        "id": "KY0nKvNGiNwd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine datasets\n",
        "# This was for CarPK and PKLot\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "mysource_train_imgs_folder = \"/content/roboflow_dataset/extracted1/train/images\"\n",
        "mydestination_train_imgs_folder = \"/content/roboflow_dataset/extracted0/train/images\"\n",
        "\n",
        "mysource_train_lbls_folder = \"/content/roboflow_dataset/extracted1/train/labels\"\n",
        "mydestination_train_lbls_folder = \"/content/roboflow_dataset/extracted0/train/labels\"\n",
        "\n",
        "mysource_test_imgs_folder = \"/content/roboflow_dataset/extracted1/test/images\"\n",
        "mydestination_test_imgs_folder = \"/content/roboflow_dataset/extracted0/test/images\"\n",
        "\n",
        "mysource_test_lbls_folder = \"/content/roboflow_dataset/extracted1/test/labels\"\n",
        "mydestination_test_lbls_folder = \"/content/roboflow_dataset/extracted0/test/labels\"\n",
        "\n",
        "mysource_valid_imgs_folder = \"/content/roboflow_dataset/extracted1/valid/images\"\n",
        "mydestination_valid_imgs_folder = \"/content/roboflow_dataset/extracted0/valid/images\"\n",
        "\n",
        "mysource_valid_lbls_folder = \"/content/roboflow_dataset/extracted1/valid/labels\"\n",
        "mydestination_valid_lbls_folder = \"/content/roboflow_dataset/extracted0/valid/labels\"\n",
        "\n",
        "sources = [mysource_train_imgs_folder, mysource_train_lbls_folder, mysource_test_imgs_folder,\n",
        "           mysource_test_lbls_folder, mysource_valid_imgs_folder, mysource_valid_lbls_folder]\n",
        "dests = [mydestination_train_imgs_folder, mydestination_train_lbls_folder, mydestination_test_imgs_folder,\n",
        "         mydestination_test_lbls_folder, mydestination_valid_imgs_folder, mydestination_valid_lbls_folder]\n",
        "\n",
        "for i in range(6):\n",
        "  for root, dirs, files in os.walk(sources[i]):\n",
        "      for file in files:\n",
        "          mysrc_file = os.path.join(root, file)\n",
        "          shutil.copy2(mysrc_file, dests[i])"
      ],
      "metadata": {
        "id": "x3A9Pv7tjkzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5:** For training only, download the starting weights for yolov7-tiny."
      ],
      "metadata": {
        "id": "XGWZHJH6uMmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download tiny model weights\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt"
      ],
      "metadata": {
        "id": "K1Dih9CubN0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6:** Configure the cfg/training/yolov7-tiny.yaml file to handle 2 or 1 classes. Also take the data.yaml file out of the extracted directory and fix the paths to point to the train/valid/test images folders (note: have to add a new line for test). Also fix the classes to 1 and delete 'space-occupied' label if needed. This data.yaml file needs to be relocated to yolov7/data directory."
      ],
      "metadata": {
        "id": "zx9JLm-tuXEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7:** Training the model. This is already setup as according to the tutorial followed. The only thing to change is the number of epochs; we used 5, 10, 20, and 30 epochs. The tutorial recommends 100 but I could not babysit the runs for that long. Make sure to download the weights file out of runs/train/exp#."
      ],
      "metadata": {
        "id": "U7dG7QLTwVtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "# v1_og - Unaltered dataset\n",
        "# v1_baw - black and white\n",
        "# v1_aug - rotated as well\n",
        "# v1_empty - just empty labels\n",
        "!python /content/yolov7/train.py --epochs 20 --workers 4 --device 0 --batch-size 32 \\\n",
        "--data data/data.yaml --img 640 640 --cfg cfg/training/yolov7-tiny.yaml \\\n",
        "--weights 'yolov7-tiny.pt' --name yolov7_tiny_spaces_fixed_res --hyp data/hyp.scratch.tiny.yaml"
      ],
      "metadata": {
        "id": "hP8aYzubbTw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8:** Test the model. Make sure to take the weights file out of runs/train/exp# and move into the outermost directory /content. Change the name of the weights argument to match this file. Make sure to download all of the resulting diagrams out of runs/test/exp#."
      ],
      "metadata": {
        "id": "GPj_egqww3hI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "!python /content/yolov7/test.py --weights best_v1_aug.pt --task test --data data/data.yaml"
      ],
      "metadata": {
        "id": "IPFYziiMbXvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optional:** While making sure everything was working, sometimes I wanted to look at individual images overlayed with their prediction. That can be done with the code below."
      ],
      "metadata": {
        "id": "Jb0pafrRyd1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make an inference and view it on the image\n",
        "!python /content/yolov7/detect.py --source \"umbc_stad_out.png\" --weights best_v2.pt\n",
        "#!python /content/yolov7/detect.py --source /content/roboflow_dataset/extracted0/test/images/2012-09-12_10_05_57_jpg.rf.5f9542ab6498fd436eef35d5ac8f5c04.jpg --weights best.pt\n",
        "#!python /content/yolov7/detect.py --source /content/2012-09-12_10_05_57_jpg.rf.5f9542ab6498fd436eef35d5ac8f5c04-blurred.jpg --weights best.pt"
      ],
      "metadata": {
        "id": "ebGydp5abcg8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}