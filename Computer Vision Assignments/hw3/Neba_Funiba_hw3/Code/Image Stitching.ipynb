{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c57456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- Compute Homography & display Keypoints -----------------------------\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def computeH(im1_pts, im2_pts):\n",
    "    M = []\n",
    "    for i in range(len(im1_pts)):\n",
    "        x, y = im1_pts[i][0], im1_pts[i][1]\n",
    "        xp, yp = im2_pts[i][0], im2_pts[i][1]\n",
    "        M.append([-x, -y, -1, 0, 0, 0, x*xp, y*xp, xp])\n",
    "        M.append([0, 0, 0, -x, -y, -1, x*yp, y*yp, yp])\n",
    "\n",
    "    M = np.array(M)\n",
    "    U, s, Vt = np.linalg.svd(M)\n",
    "    H = Vt[-1].reshape(3, 3)\n",
    "    H = H / H[2, 2]\n",
    "    return H\n",
    "\n",
    "def ransac(corr, thresh, itera):\n",
    "    max_inliers = []\n",
    "    best_H = None\n",
    "    for i in range(itera):\n",
    "        idx = np.random.choice(len(corr), 4, replace=False)\n",
    "        pic1_pts = np.float32([corr[i][0] for i in idx])\n",
    "        pic2_pts = np.float32([corr[i][1] for i in idx])\n",
    "        H = computeH(pic1_pts, pic2_pts)\n",
    "        inliers = []\n",
    "        for (pt1, pt2) in corr:\n",
    "            homog_pt1 = np.append(pt1, 1)\n",
    "            estimated_pt2 = np.dot(H, homog_pt1)\n",
    "            estimated_pt2 /= estimated_pt2[2]\n",
    "            dist = np.linalg.norm(estimated_pt2[:2] - pt2)\n",
    "            if dist < thresh:\n",
    "                inliers.append((pt1, pt2))\n",
    "        if len(inliers) > len(max_inliers):\n",
    "            max_inliers = inliers\n",
    "            best_H = H\n",
    "    return best_H\n",
    "\n",
    "def estimateH(image1_path, image2_path):\n",
    "    images = [cv2.imread(image1_path), cv2.imread(image2_path)]\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Detect keypoints and compute descriptors for each image\n",
    "    kp1, des1 = sift.detectAndCompute(images[0], None)\n",
    "    kp2, des2 = sift.detectAndCompute(images[1], None)\n",
    "\n",
    "    # Draw keypoints on images &  Display images with keypoints\n",
    "    img1_kp = cv2.drawKeypoints(images[0], kp1, None)\n",
    "    img2_kp = cv2.drawKeypoints(images[1], kp2, None)\n",
    "\n",
    "    # match and sort descriptors\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    \n",
    "    # Draw the top N matches\n",
    "    N = 100\n",
    "    img_matches_bf = cv2.drawMatches(images[0], kp1, images[1], kp2, matches[:N], None)\n",
    "    \n",
    "\n",
    "    good_matches = [m for m in matches if m.distance < 300]\n",
    "    src_points = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_points = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    corr = np.concatenate((src_points, dst_points), axis=1) \n",
    "    H = ransac(corr, thresh=5, itera=1000)\n",
    "\n",
    "    return H, img1_kp, img2_kp, img_matches_bf\n",
    "\n",
    "def stitching2(img1, img2, H):\n",
    "    img1 = cv2.imread(img1)\n",
    "    img2 = cv2.imread(img2)\n",
    "    # Note img_2 is the reference image here\n",
    "    \n",
    "    offset = 0.6\n",
    "    extension = 200\n",
    "    shift_y = 100\n",
    "    \n",
    "    # Max height and total width\n",
    "    canvasH = max(img1.shape[0], img2.shape[0]) + extension\n",
    "    canvasW = img1.shape[1] + img2.shape[1] + extension\n",
    "    \n",
    "    # Translation \n",
    "    shift = np.array([[1, 0, offset*img2.shape[1]], [0, 1, shift_y], [0, 0, 1]])\n",
    "    adjusted_H = shift @ H    \n",
    "\n",
    "    # Warp img_1\n",
    "    warped_img = cv2.warpPerspective(img1, adjusted_H, (canvasW, canvasH)).astype(np.float32)\n",
    "    \n",
    "    # Create the blank canvas and put the reference image on it\n",
    "    canvas = np.zeros((canvasH, canvasW, 3), dtype=np.float32)\n",
    "    canvas[shift_y:img2.shape[0]+shift_y, int(offset*img2.shape[1]):int((1+offset)*img2.shape[1])] = img2\n",
    "\n",
    "    # Form final stitch by adding the warped image to the canvas\n",
    "    final_stitch = canvas + warped_img\n",
    "    \n",
    "    # Normalize pixel values to the range [0, 255]\n",
    "    final_stitch = np.clip(final_stitch, 0, 255).astype(np.uint8)\n",
    "\n",
    "    return final_stitch\n",
    "\n",
    "def stitching3(img1, img2, img3, H1, H2):\n",
    "    img1 = cv2.imread(img1)\n",
    "    img2 = cv2.imread(img2)\n",
    "    img3 = cv2.imread(img3)\n",
    "    # Note img_2 is the reference image here\n",
    "    \n",
    "    offset = 0.6\n",
    "    extension = 200\n",
    "    shift_y = 100\n",
    "    \n",
    "    # Max height and total width\n",
    "    canvasH = max(img1.shape[0], img2.shape[0]) + extension\n",
    "    canvasW = img1.shape[1] + img2.shape[1] + extension\n",
    "    \n",
    "    # Translation for img 1\n",
    "    shift = np.array([[1, 0, offset*img2.shape[1]], [0, 1, shift_y], [0, 0, 1]])\n",
    "    adjusted_H = shift @ H1    \n",
    "\n",
    "    # Warp img_1\n",
    "    warped_img = cv2.warpPerspective(img1, adjusted_H, (canvasW, canvasH)).astype(np.float32)\n",
    "    \n",
    "    # Translation for img3\n",
    "    shift2 = np.array([[1, 0, offset*img2.shape[1]], [0, 1, shift_y], [0, 0, 1]])\n",
    "    adjusted_H3 = shift2 @ H2\n",
    "    \n",
    "    # Warp img_3\n",
    "    warped_img2 = cv2.warpPerspective(img3, adjusted_H3, (canvasW, canvasH)).astype(np.float32)\n",
    "\n",
    "    # Create the blank canvas and put the reference image on it\n",
    "    canvas = np.zeros((canvasH, canvasW, 3), dtype=np.float32)\n",
    "    canvas[shift_y:img2.shape[0]+shift_y, int(offset*img2.shape[1]):int((1+offset)*img2.shape[1])] = img2\n",
    "\n",
    "    # Form final stitch by adding the warped image to the canvas\n",
    "    final_stitch = canvas + warped_img + warped_img2\n",
    "    \n",
    "    # Normalize pixel values to the range [0, 255]\n",
    "    final_stitch = np.clip(final_stitch, 0, 255).astype(np.uint8)\n",
    "\n",
    "    return final_stitch\n",
    "\n",
    "\n",
    "\n",
    "image1 = \"/Users/fneba/Desktop/Hw3/keble_a.jpg\"\n",
    "image2 = \"/Users/fneba/Desktop/Hw3/keble_c.jpg\"\n",
    "reference = \"/Users/fneba/Desktop/Hw3/keble_b.jpg\"\n",
    "Homography, img1_kp, img2_kp, img_matches_bf = estimateH(image1, reference)\n",
    "\n",
    "Homography2, img1_kp2, img2_kp2, img_matches_bf2 = estimateH(image2, reference)\n",
    "\n",
    "## Display raw keypoints and matches\n",
    "\n",
    "# From image 1 and reference\n",
    "#cv2.imshow('Image 1 KP', img1_kp)\n",
    "#cv2.imshow('Reference KP', img2_kp)\n",
    "cv2.imshow('Brute-Force Matching', img_matches_bf)\n",
    "\n",
    "# From image 2 and reference\n",
    "#cv2.imshow('Image 2 KP', img1_kp2)\n",
    "#cv2.imshow('Reference KP', img2_kp2)\n",
    "#cv2.imshow('Brute-Force Matching', img_matches_bf2)\n",
    "\n",
    "# Create the mosaic from two images and their homography\n",
    "#mosaic1 = stitching2(image1, reference, Homography)\n",
    "#mosaic2 = stitching2(image2, reference, Homography2)\n",
    "\n",
    "# Show the resulting 2 image mosaic (image 1 and ref)\n",
    "#cv2.imshow(\"Mosaic1\", mosaic1)\n",
    "# Show the resulting 2 image mosaic (image 2 and ref)\n",
    "#cv2.imshow(\"Mosaic2\", mosaic2)\n",
    "\n",
    "\n",
    "# Create the panorama from 3 images and their homographies\n",
    "panorama = stitching3(image1, reference, image2, Homography, Homography2)\n",
    "\n",
    "# Show the resulting 3 image mosaic\n",
    "cv2.imshow(\"Panorama\", panorama)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey()\n",
    "\n",
    "\n",
    "# Extra Credit 1\n",
    "def crop_panorama(panorama):\n",
    "    grayscale = cv2.cvtColor(panorama, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(grayscale, 1, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find spots where there are non-black pixels\n",
    "    NB = np.argwhere(thresh > 0)\n",
    "    \n",
    "    # Get bounding box for this non-black area\n",
    "    y1, x1 = NB.min(axis=0)\n",
    "    y2, x2 = NB.max(axis=0) + 1\n",
    "    \n",
    "    # The actual cropping\n",
    "    cropping = panorama[y1:y2, x1:x2]\n",
    "    \n",
    "    return cropping\n",
    "\n",
    "#panorama = crop_panorama(panorama)\n",
    "#cv2.imshow(\"Panorama\", panorama)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "#cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b59586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------- Problem 1 last part ------------------------------\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Source for translation and rotation commands (https://learnopencv.com/image-rotation-and-translation-using-opencv/)\n",
    "def transform(image):\n",
    "\n",
    "    # translate the image by (30, 100)\n",
    "    M_1 = np.float32([[1, 0, 30], [0, 1, 100]])\n",
    "    translated = cv2.warpAffine(image, M_1, (300, 300))\n",
    "    \n",
    "    # rotate the image by 45 degrees about the center \n",
    "    M_2 = cv2.getRotationMatrix2D((150, 150), 45, 1)\n",
    "    rotated = cv2.warpAffine(translated, M_2, (300, 300))\n",
    "    \n",
    "    plt.imshow(cv2.cvtColor(rotated, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('rotated & translated Quadrilateral')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Make the 300x300 image\n",
    "image = np.zeros((300,300,3), dtype=np.uint8)\n",
    "\n",
    "# Create a white irregular quadrilateral of 50x50 in size\n",
    "corners = np.array([[120, 140], [170, 140], [175, 170], [125, 180]] , np.int32)\n",
    "\n",
    "# fill the quadrilateral white\n",
    "cv2.fillPoly(image, [corners], (255, 255, 255))\n",
    "\n",
    "plt.imshow(cv2.fillPoly(image, [corners], (255, 255, 255)))\n",
    "plt.title('original Quadrilateral')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80291d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
